# Introduction to Kafka

Legacy systems might not be the best option moving forward

*****

Snowball of data rolling toward enterprises of all sizes unless something new
is approached.

*****

1.1 What is Kafka?

*****

- Reading and writing records like a message queue
- Storing records with fault tolerance
- Processing streams as they occur

*****

The producers and consumers are completely decoupled,
allowing each client to work independently

*****

The producer can send what-ever message it wants and still have no clue about
if anyone is subscribed

*****

At-least-once semantics—A message is sent as needed until it is acknowledged.
At-most-once semantics—A message is only sent once and not resent on failure.
Exactly-once semantics—A message is only seen once by the consumer of the
message.

*****

at-least-once semantics

*****

does not receive a guarantee that it was written to the broker, the producer
can resend the message

*****

At-most-once

*****

once and never retry. In the event of a failure, the producer moves on and
doesn’t attempt to send it again

*****

exactly-once

*****

EOS

*****

logical guarantee for removing duplicate messages

*****

if the consuming application is down due to errors or maintenance

*****

When consumers start to come back online and process data, they should be able
to pick up where they left off and not drop any messages.

*****

Kafka usage

*****

why would users want to start looking at Kafka?

*****

Kafka for the developer

*****

Kafka usage is exploding

*****

to apply things they know to help them with the unknown.

*****

growing tool ecosystem all their own

*****

confronted the challenges of coupling.

*****

large number of mocks you have to create

*****

benefits of being able to decouple some of the applica-tions that we have tied
together in older designs

*****

And do those copies ever get out of date or diverge so far from the source

*****

Kafka uses topics internally to manage consumers’ offsets.

*****

why not learn Kafka Streams, ksqlDB, Apache Spark™ Streaming, or other
platforms and skip learning about core Kafka?

*****

understanding what all of the config options mean

*****

how successful Kafka was before Kafka Streams was even introduced

*****

it is import-ant to know the underlying distributed parts of your applications
and all the knobs you can turn to fine-tune your applications

*****

how Kafka handles an issue of scale by applying an interesting data struc-ture
to solve a practical problem

*****

not just limited to internal knowledge based solely on a specific workplace

*****

Explaining Kafka to your manager

*****

ability to take volumes of data and make it available for use by various
business units

*****

increased access to data is a potential outcome

*****

more data than ever flooding in

*****

how quickly that data can be turned into value

*****

Java virtual machine JVM® should be a familiar and comfortable

*****

run on premises

*****

scale horizontally

*****

Kafka myths

*****

most common misconceptions that we have run into in our work so far.

*****

Kafka only works with Hadoop®

*****

Spark Streaming and Flume are examples of tools that use Kafka

*****

Apache ZooKeeper™ is also a tool that is often found in Hadoop clusters and
might tie Kafka further to this myth.

*****

requires the Hadoop Distributed Filesystem (HDFS). That is not the case. O

*****

Kafka, replicas are not recovered by default

*****

expecting failure as a default

*****

Kafka is the same as other message brokers

*****

features that we will dig into in a bit:
 The ability to replay messages by default  Parallel processing of data

*****

one applica-tion reading a message from the message broker doesn’t remove it
from other applica-tions that might want to consume it

*****

Kafka provides a way for consumers to seek specific points and read messages
again

*****

allows for parallel processing of data and can have multiple consumers on the
same topi

*****

Kafka in the real world

*****

hard to say it does one specific function well; it excels in many specific
uses

*****

Early examples

*****

custom TCP binary protocol

*****

most of the details are in the con-figuration

*****

High availabil-ity and persistent storage are built into Kafka from the star

*****

Kafka enables robust applications to be built and helps handle the expected
failures that distributed applications are bound to r

*****

collecting events from various servers or sources is a key feature

*****

Kafka uses batching of messages for sending data

*****

as well as for writing data.

*****

Microser-vices can use Kafka as the interface for their interactions rather
than specific API

*****

When Kafka might not be the right fit

*****

only need a once-monthly or even once-yearly summary of aggregate

*****

if that amount of data is manageable to pro-cess at once as a batch

*****

access pattern for data is a mostly random lookup of data

*****

if you need the exact ordering of messages in Kafka for the entire topic

*****

if you have vast amounts of data that depend on strict ordering, there are
potential gotchas that might come into play once you notice that your
consumption is limited to one consumer per group at a time.

*****

The default message size is about 1 MB [13]. With larger messages, you start
to see memory pressure increas

*****

Online resources to get started

*****

<https://kafka.apache.org>.

*****

Confluent® <https://www.confluent.io/resources>

*****

was founded by the original Kafka’s creators
