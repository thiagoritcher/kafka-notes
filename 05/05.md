# Consumers: Unlocking data

*****

This chapters covers

- Exploring the consumer and how it works
- Using consumer groups to coordinate reading data from topics
- Learning about offsets and how to use them
- Examining various configuration options that change consumer behavior

*****

Consumers get the data from Kafka and provide those values to other systems
or applications.

*****

they can be written in various programming lan-guages just like producer
clients.

*****

An example

*****

actual consumer processes can run on sepa-rate machines and are not required
to run on a specific server.

*****

consumer is subscribing to topics (pulling messages) and not being pushed to
instead? The power of processing control shifts to the consumer in this situation.

*****

Consumers themselves control the rate of consumption.

*****

not want to have your consumers down for extended periods.

*****

how data might be removed from Kafka due to size or time limits that users
can define.

*****

## 5.1 Consumer options

*****

Table 5.1 Consumer configuration Key Purpose bootstrap.servers One or more
Kafka brokers to connect on startup value.deserializer Needed for
deserialization of the value key.deserializer Needed for deserialization of
the key group.id A name that’s used to join a consumer group client.id An ID
to identify a user (we will use this in chapter 10) heartbeat.interval.ms
Interval for consumer’s pings to the group coordinator

*****

key names is to use the con-stants provided in the Java class
ConsumerConfig (see <http://mng.bz/oGgy>) and by looking for the Importance
label of “high” in the Confluent website

*****

Let’s say that we have a specific formula that uses the time a user spends
on the page as well as the number of interactions they have,

*****

This use of deserializers for the keys and values is different than having
serializers for producers, which varies depending on the topic we consume.

*****

The reference (and more details) for the Java 8 style of using addShutdownHook
we use in the following listing can be seen at
<https://docs.confluent.io/platform/current/streams/developer-guide/write-streams.html>.

*****

Listing 5.1 Promotion consumer Defines

*****

After generating a value for every message in the topic in listing 5.1, we
find out that our modeling formula isn’t correct! So what should we do now?

*****

replay the messages we already processed.

*****

explains how time travel, in a way, is possible with Kafka.

*****

Listing 5.2 shows a consumer that runs on a thread and a different class
controls shutdown.

*****

[Listing 5.2 used](https://kafka.apache.org/26/javadoc/index.html?org/apache/kafka/clients/consumer/KafkaConsumer.html)

*****

Listing 5.2 Closing a consumer

*****

### 5.1.2 Understanding our coordinates

*****

We use offsets as index positions in the log that the consumer sends to the
broker.

*****

the flag --from-beginning.
This sets the consumer’s configuration parameter auto.offset.reset to earliest

*****

If you don’t add the option auto.offset.reset, the default is latest.
Figure 5.2 shows this mode as well. In this case, you will not see any
messages from the producer unless you send them after you start the consumer.

*****

Note that offsets always increase for each partition. Once a topic partition
has seen offset 0, even if that message is removed at a later point, the
offset number is not used again. Some of you might have run into the issue of
numbers that keep increasing until they hit the upper bound of a data type.

*****

find the partition within the topic that it was written to,

*****

then we would find the index-based offset.

*****

it is okay to have the same offset number across partitions.

*****

The ability to tell messages apart needs to include the details of which
par-tition we are talking about within a topic, as well as the offset.

*****

KIP-392 introduced this ability in version 2.4.0 [7]. As you are starting out
with your first clusters, we recommend starting with the default behavior and
only reaching for this feature as it becomes necessary to impart a real impact.

*****

If you do not have your cluster across different physical sites, you likely
will not need this feature at the current time.

*****

For each group of consumers, a specific broker takes on the role of being a
group coordinator [8]. The consumer client talks to this coordinator in order
to get a partition assignment along with other details it needs in order to
con-sume messages.

*****

The group coordinator is not only in charge of assigning which consumers read
which partitions at the beginning of group startup

*****

also when consumers are added or fail and exit the group

*****

some might ask why you don’t always choose a large number such as 500
partitions. This quest for higher throughput is not free [9]. This is why
you need to choose what best matches the shape of your data flow.

*****

many partitions might increase end-to-end latency. If milliseconds count in
your application, you might not be able to wait until a partition is
replicated between brokers

*****

This is key to having in-sync replicas, and it is done before a message is
available for delivery to a consumer. You would also need to make sure that
you watch the memory usage of your consumers. If you do not have a 1-to-1
mapping of partitions to consumers, each consumer’s memory requirements can
increase as it is assigned more partitions

*****

now the offsets are often stored inside a Kafka internal topic [10].

*****

How consumers interact

*****

Consumers that are not part of the same group do not share the same
coordination of offset knowledge.

*****

If you join an existing group (or one that had offsets stored already), your
consumer can share work with others or can even resume where it left off
reading from any previous runs

*****

Listing 5.3 Consumer configuration for consumer group group.id

*****

part of one application or as separate logic flows.

*****

same group.id as another consumer will be considered to be working together
to consume the partitions

*****

Tracking

*****

it is important that the offsets and partitions are specific to a certain
consumer group.

*****

The key coordinates to let your consumer clients work together is a unique
blend of the following: group, topic, and partition number

*****

### 5.3.1 Group coordinator

*****

As a general rule, only one consumer per consumer group can read one
partition. In other words, whereas a partition might be read by many
consumers, it can only be read by one consumer from each group at a time.

*****

when a consumer fails, the partitions that it was reading are reassigned

*****

heartbeat.interval.ms

*****

This heartbeat is the way that the consumer communi-cates with the coordinator
to let it know it is still replying in a timely fashion and work-ing
away diligently

*****

If the client isn’t running, it cannot send messages back to the group
coordinator [8].

*****

[8]

*****

### 5.3.2 Partition assignment strategy

*****

how consumers get assigned to partitions.

*****

partition.assignment.strat-egy

*****

Range and RoundRobin are provided, as are Sticky and CooperativeSticky [15].

*****

range assigner

*****

If the split is not even, then the first consumers (using alphabetical
order) get the remaining partitions

*****

if some consumer clients use all their resources, though others are fine.

*****

round-robin

*****

partitions are uniformly distributed down the row of consumers [1].

*****

The sticky strategy was added in version 0.11.0 [18]. However, since we will
use range assigner in most of our examples internally and already looked at
round-robin as well, we will not dig into Sticky and CooperativeSticky.

*****

### 5.4 Marking our place

*****

need for assuring that your applica-tions read all messages from your topic.

*****

Are you okay with sacrificing some speed in order to have a safer method of
seeing each message?

*****

set to true, the default for consumer clients

*****

enable.auto.commit

*****

Kafka brokers resend messages if they are not automatically acknowledged due
to a consumer client failure.

*****

It is possible and easy to lose messages that look like they have been
consumed despite not being processed by your consumer logic.

*****

If you need to be sure to commit a record at a specific time as you process
it or a specific offset in particular, you should make sure that you send the
offset metadata into the commit method.

*****

code-specific commits enabled by enable.auto.commit set to false.

*****

At-least-once delivery guarantees can be achieved with this pattern.

*****

your code has to handle the fact that you might have dupli-cates.

*****

commitSync, it is important to note that the commit takes place in a manner
that blocks any other progress in the code until a success or failure occurs

*****

Listing 5.5 shows how to create an asyn-chronous commit with a callback by
implementing the OffsetCommitCallback

*****

Listing 5.5 Commit with a callback

*****

consumer.commitAsync(kaOffsetMap, (map, e) -> { if

*****

Keep in mind that your latency is higher if you wait for a blocking call.

*****

fac-Listing 5.4 Waiting on a commit

*****

might be worth the delay if your requirements include needs for data
consistency

*****

These decisions help determine the amount of control you need to exercise when
informing Kafka which messages your logic considers as processed.

*****

### 5.5 Reading from a compacted topic

*****

Kafka com-pacts the partition log in a background process, and records with
the same key might be removed except for the last one.

*****

you might wonder how this concept works with an immutable log that only adds
records to the end.

*****

records from a compacted topic, consumers can still get multiple entries for
a single key

*****

We should have the logic in place to handle duplicate keys and, if needed,
ignore all but the last value

*****

### 5.6 Retrieving code for our factory requirements

*****

we want to ensure that we do not lose any audit messages when operators
complete commands against the sensors.

*****

### 5.6.1 Reading options

*****

it is possible to seek to a specific offset.

*****

starting from the beginning, going to the end, or finding offsets based on
specific times. Let’s

*****

auto.offset.reset to earli-est[24

*****

use a different group ID.

*****

Listing 5.6 Earliest offset

*****

Sometimes you just want to start your logic from when the consumers start up
and for-get about past messages

*****

Listing 5.7 Latest offset

*****

kaProperties.put("auto.offset.reset", "latest");

*****

offsetsForTimes

*****

send a map of topics and partitions as well as a timestamp for each in order
to get a map back of the offset and timestamp for the given topics and partitions

*****

Listing 5.8 Seeking to an offset by timestamps

*****

One thing to be aware of is that the offset returned is the first message with
a time-stamp that meets your criteria. However, due to the producer resending
messages on failures or variations in when timestamps are added (by consumers
, perhaps), times might appear out of order.

*****

### 5.6.2 Requirements

*****

Listing 5.9 Audit consumer logic Finds the first offset greater or equal to
that timeStampMapper Seeks to the first offset provided in kaOffsetMap Sets

*****

In this example, AlertKeySerde is used for the key to deserialize.
Because message loss isn’t a huge concern in our scenario, allowing autocommit
of messages is good enough in this situation.

*****

Listing 5.10 Alert trending consumer

*****

have any alerts quickly processed to let operators know about critical issues.

*****

Because a delay in case of other alerts is not desirable, the commit will be
for each offset in an asynchronous manner.

*****

Listing 5.11 Alert consumer Uses

*****
